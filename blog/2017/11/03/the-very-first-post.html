<html>
<head>
    <title>Ilia Zaitsev's personal site</title>
    <meta charset="utf-8"></meta>
    <link rel="stylesheet"
          href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/css/bootstrap.min.css"
          integrity="sha384-rwoIResjU2yc3z8GV/NPeZWAv56rSmLldC3R/AZzGRnGxQQKnKkoFVhFQhNUwEyJ"
          crossorigin="anonymous">
    <link rel="stylesheet"
          href="https://fonts.googleapis.com/css?family=Coda:400,800|Roboto:400,500,700|Share:400,400i,700,700i|Space+Mono:400,400i,700,700i">
    <link rel="stylesheet"
          href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/hybrid.min.css">
    <link rel="stylesheet" href="/assets/css/site.css">
</head>
<body onload="setup();">
    <div class="topmost">
        <div class="image">
            <img src="/assets/img/writings.png" width="1250">
        </div>
        <div class="text">
            <div class="title">Ilia Zaitsev</div>
            <div class="subtitle">{Software Developer & AI Enthusiast}</div>
        </div>
    </div>
    <div class="nav">
        <ul>
            <li class="about"><a href="/">About</a></li>
            <li class="home"><a href="/">Home</a></li>
            <li class="blog"><a class="active" href="#">Blog</a></li>
            <li class="projects"><a href="#">Projects</a></li>
            <li class="resume"><a href="#">Resume</a></li>
            <li class="contact"><a href="#">Contact</a></li>
        </ul>
    </div>
    <div class="container">
        <div class="container post">
    <h3 class="header centered">Deep Learning Machine Software: Ubuntu, CUDA, and TensorFlow</h3>
    <hr/>
    <article class="text main">
    <p>Recently I’ve decided to build a simple deep learning machine with single
<strong>GTX 1080Ti GPU</strong> and based on <strong>Ubuntu 16.04</strong>. The machine’s assembling process
was quite straightforward. But while deploying required software, a few
minor issues had arisen. That would be helpful to have an instruction with the list
of performed actions in case if the setup system would ever require re-deployment.</p>

<!--more-->

<div class="list-of-contents">
    <h4>Post contents</h4>
    <ul></ul>
</div>

<hr />
<h4 class="header" id="video-driver">Optional Step: Prepare Bootable USB and Install OS</h4>

<p>Of course, the first step in deploying deep learning machine based on Ubuntu OS,
you should install that operating system onto your computer. This step is thoroughly
described in <a href="https://tutorials.ubuntu.com/tutorial/tutorial-create-a-usb-stick-on-macos#0">Ubuntu Tutorials</a>
and is not mentioned here.</p>

<p>Briefly, you just need download ISO image and “burn” it onto flash drive. If your
host machine works under macOS, <a href="https://tutorials.ubuntu.com/tutorial/tutorial-create-a-usb-stick-on-macos#0">the following tutorial</a>
describes how to create bootable stick.</p>

<hr />
<h4 class="header" id="disable-ui">Disabling Graphical Interface and CLI Mode Preparations</h4>

<p>If desktop version of Ubuntu was installed, then by default the user will be
logged into graphical mode. That is not what one would like to have if wants to use
created machine as a deep learning computations host. To prepare system for a
remote control and CLI mode, one need to setup <strong>OpenSSH</strong> server, and disable
UI desktop to log into terminal.</p>

<blockquote class="warning">
    <strong>Warning:</strong> After applying the following steps and system's
    reboot, UI will not be available anymore. The UI daemon should be re-enabled,
    and <strong>GRUB</strong> configuration file changed back to video mode to
    restore graphical desktop.
</blockquote>

<p>First of all, check if <code class="highlighter-rouge">openssh-server</code> is installed on the machine. Otherwise,
install it (and adjust configuration, if required):</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>apt install openssh-server
<span class="nv">$ </span><span class="nb">sudo </span>service ssh status
<span class="nv">$ </span><span class="nb">sudo </span>vim /etc/ssh/sshd_config
</code></pre></div></div>

<p>To get an IP address which is assigned to the host by router, the command
<code class="highlighter-rouge">ifconfig -a</code> could be used. It should return a list of network devices and
local IP address.</p>

<p>When everything is installed, and the machine is ready to be used in “headless”
mode, one should change <strong>GRUB</strong> loader configuration a bit and disable <code class="highlighter-rouge">lightdm</code>.
To update boot loader configuration, edit <code class="highlighter-rouge">/etc/default/grub</code> file:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>apt install vim  <span class="c"># nano editor could be used instead</span>
<span class="nv">$ </span><span class="nb">sudo </span>vim /etc/default/grub
<span class="nv">$ </span><span class="nb">sudo </span>update-grub
</code></pre></div></div>

<p>Here is an example of configuration file’s content when the host was
completely prepared for “headless” run (a couple of commented out strings were
used when desktop UI was enabled):</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># If you change this file, run 'update-grub' afterwards to update</span>
<span class="c"># /boot/grub/grub.cfg.</span>
<span class="c"># For full documentation of the options in this file, see:</span>
<span class="c">#   info -f grub -n 'Simple configuration'</span>

<span class="nv">GRUB_DEFAULT</span><span class="o">=</span>0
<span class="nv">GRUB_HIDDEN_TIMEOUT</span><span class="o">=</span>0
<span class="nv">GRUB_HIDDEN_TIMEOUT_QUIET</span><span class="o">=</span><span class="nb">true
</span><span class="nv">GRUB_TIMEOUT</span><span class="o">=</span>10
<span class="nv">GRUB_DISTRIBUTOR</span><span class="o">=</span><span class="sb">`</span>lsb_release <span class="nt">-i</span> <span class="nt">-s</span> 2&gt; /dev/null <span class="o">||</span> <span class="nb">echo </span>Debian<span class="sb">`</span>
<span class="c"># GRUB_CMDLINE_LINUX_DEFAULT="quiet splash"</span>
<span class="nv">GRUB_CMDLINE_LINUX_DEFAULT</span><span class="o">=</span><span class="s2">"text"</span>
<span class="c"># GRUB_CMDLINE_LINUX="nomodeset"</span>
<span class="nv">GRUB_CMDLINE_LINUX</span><span class="o">=</span><span class="s2">"text"</span>
<span class="nv">GRUB_TERMINAL</span><span class="o">=</span>console
</code></pre></div></div>

<p>And, the final step:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>systemctl disable lightdm
<span class="nv">$ </span>reboot
</code></pre></div></div>

<hr />
<h4 class="header" id="generate-ssh">Generate SSH Key and Upload to the Host</h4>

<p>When you connect to your deep learning machine via SSH, each time you need to
enter your credentials. To simplify this process a bit, you can generate public/private
keys pair to access without typing password and username.</p>

<p>To do it, on your machine which you’re going to use to control the deep
learning host, generate an SSH keypair with <code class="highlighter-rouge">ssh-keygen</code>, copy public key to host,
and add private key to <code class="highlighter-rouge">ssh-agent</code> (don’t forget to replace placeholders in the
following script with actual values):</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> <span class="nb">cd</span> ~/.ssh
<span class="o">&gt;</span> ssh-keygen <span class="nt">-t</span> rsa  <span class="c"># follow keygen instructions to generate key</span>
<span class="o">&gt;</span> <span class="nb">cat </span>YOUR-KEY-NAME.pub | ssh USERNAME@IP_ADDRESS <span class="s1">'cat &gt;&gt; .ssh/authorized_keys &amp;&amp; echo "Key copied"'</span>
<span class="o">&gt;</span> ssh-add <span class="nt">-K</span> YOUR-KEY-NAME <span class="o">&gt;</span>/dev/null 2&gt;&amp;1  <span class="c"># or add this line to your .bashrc, .zshrc, etc.</span>
</code></pre></div></div>

<p>Now you’re able to connect to your host just typing something
like <code class="highlighter-rouge">ssh username@$192.186.0.10</code> without entering credentials or providing
path to the key.</p>

<hr />
<h4 class="header" id="anaconda">Installing Anaconda</h4>

<p>When everything is prepared, we’re going to install <a href="https://www.anaconda.com/distribution/">Anancoda</a> Python’s distribution. It is not required to use <strong>Anaconda</strong> to install TensorFlow or
any other “scientific” Python package, but this package management system makes
process a bit easier sometimes.</p>

<p>To install <strong>Anaconda</strong> distribution on your host, run the following commands (adjust
the first line as needed to pick another version):</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">export </span><span class="nv">conda_version</span><span class="o">=</span><span class="s2">"Anaconda3-5.0.0.1-Linux-x86_64"</span>
<span class="nv">$ </span>wget <span class="s2">"https://repo.continuum.io/archive/</span><span class="k">${</span><span class="nv">conda_version</span><span class="k">}</span><span class="s2">.sh"</span> <span class="nt">-O</span> anaconda3.sh
<span class="nv">$ </span>chmod +x anaconda3.sh
<span class="nv">$ </span>./anaconda3.sh
<span class="nv">$ </span>python
Python 3.6.2 |Anaconda, Inc.| <span class="o">(</span>default, Sep 30 2017, 18:42:57<span class="o">)</span>
<span class="o">[</span>GCC 7.2.0] on linux
Type <span class="s2">"help"</span>, <span class="s2">"copyright"</span>, <span class="s2">"credits"</span> or <span class="s2">"license"</span> <span class="k">for </span>more information.
<span class="o">&gt;&gt;&gt;</span>
</code></pre></div></div>

<hr />
<h4 class="header" id="tf-and-cuda">Installing CUDA (+cuDNN) Drivers and TensorFlow</h4>

<p>To run TensorFlow on GPU, CUDA driver and cuDNN libraries should be installed. All required
software is available from <a href="https://developer.nvidia.com/deep-learning">NVIDIA developers platform</a>.
The CUDA driver could be downloaded via terminal:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>wget <span class="s2">"https://developer.nvidia.com/compute/cuda/8.0/prod/local_installers/cuda_8.0.44_linux-run"</span> <span class="nt">-O</span> cuda_8.0.44_linux.run
</code></pre></div></div>

<p>But to download cuDNN library, you need navigate to portal using your browser and sing up. You’ll get a confirmation email and then will be able to sing in. Afterwards, go to <a href="https://developer.nvidia.com/rdp/cudnn-download">cuDNN download page</a> and get an appropriate version of drivers.</p>

<blockquote class="tip">
    <strong>Note:</strong> In general, different versions of <strong>TensorFlow</strong>
    require different versions of cuDNN headers. For example, <strong>v1.0</strong>
    (and lower) requires cuDNN v5.1, but version <strong>v1.3</strong> requires cuDNN v6.0.
    You'll see an error message when importing library if versions don't match.
</blockquote>

<p>As soon as drivers downloaded, install run CUDA installer. Note that it asks you if
you want to install video driver. You don’t need to do it, because a prepacked driver
could be outdated, and install driver yourself via Ubuntu package manager:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>sh cuda_8.0.44_linux.run <span class="nt">--override</span>
<span class="nv">$ </span><span class="nb">sudo </span>add-apt-repository ppa:graphics-drivers/ppa
<span class="nv">$ </span><span class="nb">sudo </span>apt-get update
<span class="nv">$ </span><span class="nb">sudo </span>apt-get purge nvidia-<span class="k">*</span>
<span class="nv">$ </span><span class="nb">sudo </span>apt-get purge nvidia-cuda<span class="k">*</span>
<span class="nv">$ </span><span class="nb">sudo </span>apt-get install nvidia-384  <span class="c"># or any other recent version of driver</span>
<span class="nv">$ </span>which nvcc
<span class="nv">$ </span>nvidia-smi
</code></pre></div></div>

<p>By default, CUDA drivers installed into <code class="highlighter-rouge">/usr/local/cuda-8.0/</code> directory. Unpack
downloaded cuDNN archive and copy library and headers into CUDA folder:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">tar </span>xvzf cudnn-8.0-linux-x64-v6.0.tgz
<span class="nb">sudo </span>cp <span class="nt">-P</span> cuda/include/libcudnn<span class="k">*</span> /usr/local/cuda-8.0/include
<span class="nb">sudo </span>cp <span class="nt">-P</span> cuda/lib64/libcudnn<span class="k">*</span> /usr/local/cuda-8.0/lib64
<span class="nb">sudo </span>chmod a+r /usr/local/cuda-8.0/include/cudnn.h /usr/local/cuda-8.0/lib64/libcudnn<span class="k">*</span>
</code></pre></div></div>
<p>A key <code class="highlighter-rouge">-P</code> in <code class="highlighter-rouge">cp</code> command is required to copy symlinks in <code class="highlighter-rouge">.so</code> files.</p>

<p>That’s all. Now drivers and library are ready. Next, add the following environment
variables to your <code class="highlighter-rouge">.bashrc</code> so TensorFlow loader can find installed software:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># CUDA/cuDNN</span>
<span class="nb">export </span><span class="nv">CUDA_HOME</span><span class="o">=</span><span class="s2">"/usr/local/cuda-8.0"</span>
<span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="s2">"/usr/local/cuda-8.0/bin:</span><span class="nv">$PATH</span><span class="s2">"</span>
<span class="nb">export </span><span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="s2">"/usr/local/cuda-8.0/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64:</span><span class="nv">$LD_LIBRARY_PATH</span><span class="s2">"</span>
<span class="c"># Suppress TF debugging info</span>
<span class="c"># TF_CPP_MIN_LOG_LEVEL=3</span>
</code></pre></div></div>

<p>The final step - create Python environment and install GPU version of TensorFlow:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>conda create <span class="nt">-n</span> deep <span class="nv">python</span><span class="o">=</span>3.6
<span class="nv">$ </span><span class="nb">source </span>activate deep
<span class="nv">$ </span>pip install tensorflow-gpu<span class="o">==</span>1.3  <span class="c"># change to newer/older versions if required</span>
<span class="nv">$ </span>python <span class="nt">-c</span> <span class="s2">"import tensforflow as tf; print(tf.__version__)"</span>
</code></pre></div></div>

<p>If there are no errors - everything was done right, and now you can train deep
models on GPU. As a final check, run the following script:</p>
<pre><code class="language-Python">import tensorflow as tf
const = tf.Constant('Hello World!')
with tf.Session() as session:
    output = session.run(const)
print(output)
</code></pre>

<p>If you don’t suppress TF debugging info output, you’ll see a notification about
 available GPU/GPUs and memory after library’s import.</p>

<hr />
<h3 id="references">References</h3>

<ol>
    <li>
        <a href="https://askubuntu.com/questions/799184/how-can-i-install-cuda-on-ubuntu-16-04">
            How can I install CUDA on Ubuntu 16.04?
        </a>
    </li>
    <li>
        <a href="https://askubuntu.com/questions/767269/how-can-i-install-cudnn-on-ubuntu-16-04">
            How can I install CuDNN on Ubuntu 16.04?
        </a>
    </li>
    <li>
        <a href="https://stackoverflow.com/questions/31326015/how-to-verify-cudnn-installation/36978616#36978616">
            How to verify cuDNN installation?
        </a>
    </li>
    <li>
        <a href="https://www.tensorflow.org/install/install_linux#InstallingNativePip">
            Installing TensorFlow on Ubuntu with native PIP
        </a>
    </li>
    <li>
        <a href="https://developer.nvidia.com/deep-learning">
            NVIDIA Deep Learning Portal</a>
    </li>
</ol>

    </article>    
</div>

    </div>
    <footer class="footer">
        Each page has this footer, and it is 18 Nov 2017 today
    </footer>
    <script src="https://code.jquery.com/jquery-3.1.1.slim.min.js"
            integrity="sha384-A7FZj7v+d/sdmMqp/nOQwliLvUsJfDHW+k9Omg/a/EheAdgtzNs3hpfag6Ed950n"
            crossorigin="anonymous">
    </script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tether/1.4.0/js/tether.min.js"
            integrity="sha384-DztdAPBWPRXSA/3eYEEUWrWCy7G5KFbe8fFjk5JAIxUYHKkDx6Qin1DkWx51bBrb"
            crossorigin="anonymous">
    </script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/js/bootstrap.min.js"
            integrity="sha384-vBWWzlZJ8ea9aCX4pEW3rVHjgjt7zpkNpZk+02D9phzyeVkE+jo0ieGizqPLForn"
            crossorigin="anonymous">
    </script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script src="/lib/site.js"></script>
</body>
</html>
